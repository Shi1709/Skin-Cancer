{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a34f998-b132-4a9c-8355-1517c0f28a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OS libs\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "#Data handling tools\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "#Deep learning libs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D , MaxPooling2D , Flatten , Activation , Dense , Dropout , BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam , Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "#Warningds\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e82bf-e2c7-4ea3-902d-db3026e7bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = r\"C:\\Users\\SHISHIR\\Desktop\\EPICS\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train\"\n",
    "\n",
    "\n",
    "\n",
    "filepaths =[]\n",
    "labels = []\n",
    "\n",
    "folds = os.listdir(train_data_path)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(train_data_path , fold)\n",
    "    filelists = os.listdir(f_path)\n",
    "    \n",
    "    for file in filelists:\n",
    "        filepaths.append(os.path.join(f_path , file))\n",
    "        labels.append(fold)\n",
    "        \n",
    "#Concat data paths with labels\n",
    "Fseries = pd.Series(filepaths , name = 'filepaths')\n",
    "Lseries = pd.Series(labels , name = 'label')\n",
    "train_df = pd.concat([Fseries, Lseries],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2c07f-13c3-47a1-bc21-807b9fc6eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461335-f3cf-4b35-9d59-30a13332eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = r\"C:\\Users\\SHISHIR\\Desktop\\EPICS\\Skin cancer ISIC The International Skin Imaging Collaboration\\Test\"\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "folds = os.listdir(test_data_path)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(test_data_path,fold)\n",
    "    file_lists = os.listdir(f_path)\n",
    "    \n",
    "    \n",
    "    for file in file_lists:\n",
    "        filepaths.append(os.path.join(f_path,file))\n",
    "        labels.append(fold)\n",
    "        \n",
    "#Concat data paths with labels\n",
    "Fseries = pd.Series(filepaths , name = 'filepaths')\n",
    "Lseries = pd.Series(labels , name = 'label')\n",
    "test_df = pd.concat([Fseries,Lseries],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ec207-b153-4127-99d4-64b03d863f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26076086-864f-4701-a689-f40e870833c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid,test = train_test_split(test_df,train_size=0.5,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793986c-4c1c-4a52-a707-ddf4689f06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224 ,244)\n",
    "batch_size = 16\n",
    "\n",
    "tr_gen = ImageDataGenerator()\n",
    "ts_gen= ImageDataGenerator()\n",
    "\n",
    "train_gen = tr_gen.flow_from_dataframe(train_df , x_col = 'filepaths' , y_col = 'label' , target_size = img_size ,\n",
    "                                      class_mode = 'categorical', color_mode = 'rgb', shuffle = True, batch_size=batch_size)\n",
    "\n",
    "valid_gen = ts_gen.flow_from_dataframe(valid , x_col = 'filepaths' , y_col = 'label' , target_size = img_size , \n",
    "                                       class_mode = 'categorical',color_mode = 'rgb', shuffle= True, batch_size=batch_size)\n",
    "\n",
    "test_gen = ts_gen.flow_from_dataframe(test , x_col= 'filepaths' , y_col = 'label' , target_size = img_size , \n",
    "                                      class_mode = 'categorical', color_mode= 'rgb', shuffle = False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f7011-b45a-491a-84de-0f5b3519795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dict = train_gen.class_indices\n",
    "classes = list(gen_dict.keys())\n",
    "images , labels = next(train_gen)\n",
    "\n",
    "plt.figure(figsize= (20,20))\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    image = images[i] / 255\n",
    "    plt.imshow(image)\n",
    "    index = np.argmax(labels[i])\n",
    "    class_name = classes[index]\n",
    "    plt.title(class_name , color = 'blue' , fontsize= 12)\n",
    "    plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18bcb22-807d-4021-b5d4-54650c2ede39",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (img_size[0] , img_size[1] , 3)\n",
    "num_class = len(classes)\n",
    "\n",
    "base_model = tf.keras.applications.efficientnet.EfficientNetB7(include_top = False , weights = 'imagenet' ,\n",
    "                                                               input_shape = img_shape, pooling= 'max')\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis= -1 , momentum= 0.99 , epsilon= 0.001),\n",
    "    Dense(256, kernel_regularizer=regularizers.l2(0.016), activity_regularizer=regularizers.l1(0.006),\n",
    "      bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
    "    Dropout(rate= 0.4 , seed = 75),\n",
    "    Dense(num_class , activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(Adamax(learning_rate = 0.001) , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241366ed-57d8-464c-aaaa-d1df7cf6ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 10\n",
    "\n",
    "history = model.fit(x= train_gen , epochs = Epochs , verbose = 1 , validation_data = valid_gen ,\n",
    "                   validation_steps=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6773a6-edf2-4e32-bc3f-bdac85d382ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "\n",
    "index_acc = np.argmax(val_acc)\n",
    "val_highest = val_acc[index_acc]\n",
    "\n",
    "Epochs = [i+1 for i in range(len(train_acc))]\n",
    "\n",
    "loss_label = f'Best epochs = {str(index_loss+1)}'\n",
    "acc_label = f'Best epochs = {str(index_acc+1)}'\n",
    "plt.figure(figsize= (20,8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(Epochs , train_loss , 'r' , label = 'Training Loss')\n",
    "plt.plot(Epochs , val_loss , 'g' , label = 'Validation Loss')\n",
    "plt.scatter(index_loss + 1 , val_lowest , s = 150 , c = 'blue',label = loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(Epochs , train_acc , 'r' , label = 'Training Accuracy')\n",
    "plt.plot(Epochs , val_acc , 'g' , label = 'Validation Accuracy')\n",
    "plt.scatter(index_acc + 1 , val_highest , s = 150 , c = 'blue',label = acc_label)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15956cf3-59eb-47bd-ab03-1527010069f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(train_gen , steps =16 , verbose = 1)\n",
    "valid_score = model.evaluate(valid_gen , steps = 16 , verbose = 1)\n",
    "test_score = model.evaluate(test_gen , steps = 16 , verbose = 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \",train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \",valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \",test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705c099-a96d-4a7d-a1f7-1ef0ad46051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_gen)\n",
    "\n",
    "\n",
    "y_pred = np.argmax(preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ce443-73cd-4f8a-90d2-493e7f9ab4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dict = test_gen.class_indices\n",
    "classes = list(g_dict.keys())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "\n",
    "plt.figure(figsize= (10, 10))\n",
    "plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation= 45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j],horizontalalignment= 'center',color= 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fecda7f-aa77-4dbd-8693-f06c7e93bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Report\n",
    "print(classification_report(test_gen.classes, y_pred , target_names= classes ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e708a6-819d-408d-a000-fc9774a99bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545ad49-027f-4a1a-ad6e-620c72a0153b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16fefd-a47b-4520-befe-100801940cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93a12f-ffb8-481e-b527-9e4dde113c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
